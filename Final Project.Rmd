---
title: "Group 9 Final Project: NYC Taxi-FHV Analysis"
author: "Jie Li, Xiaofan Zhang"
date: "April 25, 2019"
output:
  html_notebook:
    code_folding: hide
  html_document:
    df_print: paged
---

## I. Introduction
This is a comprehensive Exploratory Data Analysis for 300 millions of for-hire vehicle (Uber, Lyft, Via) trips originating in New York City from **2018-01-01** to **2018-12-31**. We are focusing on the trip counts and duration in the different time windows to find out the data insights and user behavior. All the data analysis process has been uploaded to [GitHub](https://github.com/Jay4869/NYC-Taxi-FHV-Project).

The goal of this challenge is to process large data sets and to understand the duration of FHV in NYC based on features: trip location, pick-up, drop-off time, and weather effect. Also, we are interested in the difference betweeen three companies such as market shares, targeted customers, and business strategy. First of all, we analysis and visualize the original data, engineer new features, aggregate time-series variables to understand the data and pattern. Second, we compare three companies (Uber, Lyft, Via) over various time frame on trip amount and duration to analyze the market share and business strategy. Lastly, we add external NYC weather data to study how the weather impact on the trip duration and order requests in order to understand users behavior.

## II. Description of the data source
The [raw data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) were collected and provided to the NYC Taxi and Limousine Commission (TLC) by technology providers authorized under the Taxicab & Livery.

The For-Hire Vehicle ("FHV") trip records since 2009 until present including fields capturing the dispatching base license number and the pick-up date, time, and taxi zone location ID. We are focusing on the time period from **2018-01-01** to **2018-12-31**, so the data comes in the shape of 200+ million observations, and each row contains one trip infomation.

The base license number is matching with different vehicle companies, so that we will join the `base-number` file to define the vehicle types, and we only focus on Uber, Lyft, Via at this point.

The [NYC Taxi Zones map](https://data.cityofnewyork.us/Transportation/NYC-Taxi-Zones/d3c5-ddgc) provided by TLC and published to NYC Open Data. This map shows the NYC taxi zones corresponding to the pick up zomes and drop off zones, or location IDs, included in the FHV trip records. The taxi zones are roughly based on NYC Department of City Planning's Neighborhood Tabulation Areas (NTAs) and are meant to approximate neighborhoods.

The [NYC Weather data](https://www.ncdc.noaa.gov/data-access) is provided by National Centers For Environmental. NCEI is the world's largest provider of weather and climate data. Land-based, marine, model, radar, weather balloon, satellite, and paleoclimatic are just a few of the types of datasets available. The weather data we are using is collected from NY Central Park Station (USW00094728) from **2018-01-01** to **2018-12-31**, which contains daily weather records such as wind, precipitation, snow and snow depth.

Statistics through January 1 to December 31, 2018:

* 17.2 GB of raw data
* 200+ million for-hire vehicle total trips
* 365 daily weather records

Existing problem:

* R reads entire data set into RAM all at once. Total 17.2 GB of raw data would not fit in local memory at once.
* R Objects live in memory entirely, which cause slowness for data analysis.
* The TLC publishes base trip record data as submitted by the bases, and we cannot guarantee or confirm their accuracy or completeness.


## III. Description of data import / cleaning / transformation
### 3.1 Libraries and Dependencies

We list libraries for our data process, manipulation and visualization.
```{r, warning=F, message=F}
library(tibble) # data wrangling
library(reshape2) # data wrangling
library(tidyr) # data wrangling
library(dplyr) # data manipulation
library(purrr) # data manipulation
library(data.table) # data manipulation
library(ggplot2) # visualization
library(plotly) # visualization
library(lubridate) # date and time
```

```{r, echo=F}
setwd("E:/NYC Taxi Project/")
```

### 3.2 Data collection

We write a `shell` script to download raw data from public NYC TLC websites
```{r, eval=F}
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-01.csv >201801.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-02.csv >201802.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-03.csv >201803.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-04.csv >201804.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-05.csv >201805.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-06.csv >201806.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-07.csv >201807.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-08.csv >201808.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-09.csv >201809.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-10.csv >201810.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-11.csv >201811.csv
curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-12.csv >201812.csv
```

### 3.3 Data Import & Cleaning

We use `data.table:fread` function to speed up loading data for each month, and select the vehicle company (Uber, Lyft, Via) based on the license number. At the time, we also export subset monthly data into `csv` file as back up. we combine all monthly data into `tibble` format to perform our strucuted data. Each row contains trip information such as pick-up, drop-off date, time, location ID.

Due to local memeory issue in R, we process half-year data at one time, and use **aggregation** technique to compute results and perform entire year analysis. We will explain more detail below.

```{r, eval=F}
base = read.csv("../Data/original/base_number.csv")$x %>% as.character()

load = function(i)
{
  # set file path 
  x = paste("../Data/original/2018", i, ".csv") %>% gsub(" ", "", .)
  
  # load orginal data
  # identify type
  # remove useless columns
  temp = fread(x) %>%
    filter(Dispatching_base_number %in% c("B02510", "B02800", base)) %>%
    mutate(type = ifelse(Dispatching_base_number == "B02510", "Lyft",
                         ifelse(Dispatching_base_number == "B02800", "Via", "Uber"))) %>%
    select(-SR_Flag, -Dispatching_base_number, -Dispatching_base_num) %>%
    as.tibble()
  
  # export subset monthly data as back-up
  a = paste("../Data/tables/", i, ".csv") %>% gsub(" ", "", .)
  write.csv(temp, a)

  return(data)
}

data = c()
for(i in 1:12)
{
  # load original monthly data
  temp = load(i)
  
  # combine data
  data = bind_rows(data, temp)
  
  # optimize memory usage
  remove(temp)
}
```

### 3.4 File structure and content

Let's have an overview of the first 5000 `Jan` and `Dec` data. We find the time format is different, so we would like to work on variable convertion and transformation such as standard time stamp.

```{r, echo=F}
Jan = read.csv("./Data/tables/1.csv") %>% select(-X)
Dec = read.csv("./Data/tables/12.csv") %>% select(-X)

Jan
Dec
```

### 3.5 Data Transformation
Next, we use `lubridate:ymd_hms` and `lubridate:mdy_hms` transformat string to standard time stamp variables, and calucate the trip duration in **minute** by sbustracting drop-off time and pick-up time. Also, we factorize the company types to save memory usage and furture visualization.

```{r}
# Jan-Nov
Jan %>%
mutate(pick = ymd_hms(Pickup_DateTime), drop = ymd_hms(DropOff_datetime), duration = as.numeric(drop - pick)/60, type = factor(type)) %>%
select(-V1, -Pickup_DateTime, -DropOff_datetime)

# only for Dec
Dec %>%
mutate(pick = mdy_hm(Pickup_DateTime), drop = mdy_hm(DropOff_datetime), duration = as.numeric(drop - pick)/60, type = factor(type)) %>%
select(-V1, -Pickup_DateTime, -DropOff_datetime)
```

The density plot shows the duration distribution has a significantly right skew.
```{r, fig.width=8, fig.height=4, results="hide"}
df = fread("./Data/orignal/sample duration.csv")

density1 = density(df$value)
plot_ly(x = ~ density1$x, y = ~ density1$y, type = 'scatter', mode = 'lines', name = 'Fair cut', fill = 'tozeroy') %>%
  layout(title = "Density Plot for Trip Duration",
    xaxis = list(title = 'Duration'),
         yaxis = list(title = 'Density'))
```

We require to take **log** transformation on the duration to solve the skewness issue to normal distribution for furture modeling and statistical inference.

```{r, fig.width=8, fig.height=4}
density1 = density(log(df$value))
plot_ly(x = ~ density1$x, y = ~ density1$y, type = 'scatter', mode = 'lines', name = 'Fair cut', fill = 'tozeroy') %>%
  layout(title = "Density Plot for Transformated Trip Duration",
    xaxis = list(title = 'Log(Duration)'),
         yaxis = list(title = 'Density'))
```


### 3.6 Data Missing & Outliers

Due to most companies allow to cancel the order in 2 minutes, and drives might miss the passengers in order to cancel the order. We use **heat map** to visualize the trips counts based on the pick-up and drop-off location in order to identify the possiblity.

```{r, echo=F}
df = read.csv("./Data/tables/less_than_2.csv")
df2 = read.csv("./Data/tables/large_than_240.csv")
pick = read.csv("./Data/tables/dictionary_pickup.csv") %>% as.tibble()
drop = read.csv("./Data/tables/dictionary_dropoff.csv") %>% as.tibble()

match_zone = function(df,dictionary_pickup,dictionary_dropoff)
{

  matched.df = df %>% 
   left_join(dictionary_pickup,by="PUlocationID") %>% 
   mutate(pick_borough = borough) %>% 
   select(-borough)%>%
   left_join(dictionary_dropoff,by="DOlocationID") %>% 
   mutate(drop_borough = borough) %>%  
  select(-borough) %>% 
   filter(!is.na(drop_borough)) %>% 
   filter(!is.na(pick_borough)) %>% 
  group_by(pick_borough,drop_borough) 

  return(matched.df)
}

df = match_zone(df,pick,drop) %>% count() %>% mutate(counts = n)

df2 = match_zone(df2,pick,drop) %>% count() %>% mutate(counts = n)
```

```{r, fig.width= 8, fig.height= 4}
vals = unique(scales::rescale(df$counts))
o = order(vals, decreasing = FALSE)
cols = scales::col_numeric("Reds", domain = NULL)(vals)
colz = setNames(data.frame(vals[o], cols[o]), NULL)
plot_ly(data=df, x=~pick_borough,y=~drop_borough,z=~counts, colorscale = colz, type = "heatmap") %>% layout(title = "Duration is less than 2 minutes", xaxis = list(title = "Pick-up Borough"), yaxis = list(title = "Drop-off Borough"))
```

```{r, fig.width= 8, fig.height= 4}
vals = unique(scales::rescale(df2$counts))
o = order(vals, decreasing = FALSE)
cols = scales::col_numeric("Reds", domain = NULL)(vals)
colz = setNames(data.frame(vals[o], cols[o]), NULL)
plot_ly(data=df2, x=~pick_borough,y=~drop_borough,z=~counts, colorscale = colz, type = "heatmap") %>%
layout(title = "Duration is larger than 4 hours", xaxis = list(title = "Pick-up Borough"), yaxis = list(title = "Drop-off Borough"))
```


```{r, eval=F}
data[which(is.na(data)), ]
```

```{r, echo=F}
read.csv("./Data/tables/missing.csv") %>% as.tibble() %>% mutate(pick = mdy_hm(pick), drop = mdy_hm(drop))
```

We find:

* There are 279,693 trip records are less than 2 minutes duration, which might be incorrect or cancelled request.
* Also, there are 7900+ trips have duration longer than 4 hours, which does not make sense for close borough.
* There are missing values when pick-up location is EWR in our dataset. More specific, there are 91,932 records missing pick-up location. To conclude accurate analysis, we are going to remove all `NA` records.


### 3.7 Data Aggregation
By Solving local memory issue in R, since we are interested in the number of trips, and trip duraction, we don't have to store all data into R. The idea is that we can process half-by-half year data and aggregate into different levels such as hour, weekday, day, and month. Then, we combine aggregated results to make visualization plots, which are much smaller.

```{r, eval=F}
data %>%
    mutate(hour = hour(pick), wday = weekdays(pick), type) %>%
    group_by(hour, wday, type) %>%
    count
```

```{r, echo=F}
read.csv("./Data/tables/counts by h_wk_type.csv") %>% select(-X) %>% as.tibble()
```

```{r, eval=F}
data %>%
    mutate(month = month.abb[month(pick)]) %>%
    group_by(month, type) %>%
    summarise(d.med = median(duration))
```

```{r, echo=F}
read.csv("./Data/tables/month type duration.csv") %>% select(-X) %>% as.tibble()
```

## V. Results

### 5.1 Overall Median Duration

We look at overall median trip duration based on hour, weekday and month bases. The median is more robust measurement because it has less effect on outliers. Hourly base is showing the peak hour effects in a typical day. The weekly base tells the difference between work day and weekends. The monthly base has a good explaination on seasonality.

```{r, message=F, warning=F, results="hide", fig.width= 8, fig.height= 4}
p1 = read.csv("./Data/tables/hourly duration.csv") %>%
plot_ly(., x = ~ hour, y = ~ d.med, type ="scatter", mode = 'lines+markers',line = list(color="#2E86C1", width = 4), marker = list(size = 8, color = 'rgba(255, 182, 193, .9)', line = list(color = 'rgba(152, 0, 0, .8)', width = 2,simplyfy = F)), text = ~ paste("Hour: ", hour, '<br>Average duration:', round(d.med,2)), main="average duration vs hour") %>%
  layout(title = 'Hourly Median Trip Duration', yaxis = list(title = 'Duration (min)',range=c(15,25), zeroline = FALSE),
         xaxis = list(title = 'Hour',zeroline = FALSE))

lvl = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")

p2 = read.csv("./Data/tables/wday duration.csv") %>%
  mutate(wday = ordered(wday, levels = lvl)) %>%
  arrange(wday) %>%
  plot_ly(., x = ~ wday, y = ~ d.med, type ="scatter", mode = 'lines+markers',
          line = list(width=4,simplyfy = F, color='rgb(114, 186, 59)'),
          marker = list(size = 8, color = '#8E44AD', line = list(color = '#3498DB', width = 2)),
          text = ~paste("Weekday: ", wday, '<br>Median duration:', round(d.med,2))) %>%
  layout(title = 'Weekday Median Trip Duration',
         yaxis = list(title = 'Duration (min)', range=c(15,25), zeroline = FALSE),
         xaxis = list(title = 'Weekday', zeroline = FALSE))

p3 = read.csv("./Data/tables/month duration.csv") %>%
  mutate(month = ordered(month, levels = month.abb)) %>%
  arrange(month) %>%
  plot_ly(., x = ~ month, y = ~ d.med, 
        type ="scatter",mode = 'lines+markers', line=list(color="#FF5733",width = 4),
        marker = list(size = 8, color = '#FFFF00', line = list(color = '#E67E22', width = 2)),
        text = ~paste("Month: ",month, '<br>Average duration:', round(d.med,2))) %>%
  layout(title = 'Median Trip Duration(min)', showlegend = F,
         yaxis = list(title = 'Duration',range=c(15,25), zeroline = FALSE),
         xaxis = list(title = 'Month', zeroline = FALSE))

subplot(p1, p2, p3, nrows = 3)
```
We find:

* After mid-night, the shortest trip duration is falling down and reaching 16 minutes; the peak trip duration occurs during 6 AM - 6 PM about 20+ minutes in a typical day, and the longest trip duration is 24 minutest at 4 PM (interesting!)
* For the weekday, the longest trip duration occurs on Thursday, and weekends have the lowest trip duration. We guess maybe more people prefer to stay at home on the weekends.
* The higher trip duration occurs in May and Oct, and the lower happens in Jan. The spring and fall are the best weather for traveling and visitors in NYC, so it might cause traffic.

### 5.2 Durations of FHV Types

We investigate on how the median trip duration depends on the different for hire vehicle types such as Uber, Lyft and Via in hourly, weekly and monthly bases.

```{r, echo=F}
accumulate_by = function(dat, var)
{
  var = lazyeval::f_eval(var, dat)
  lvls = plotly:::getLevels(var)
  dats = lapply(seq_along(lvls), function(x) {cbind(dat[var %in% lvls[seq(1, x)], ], frame = lvls[[x]])})
  dplyr::bind_rows(dats)
}
```

```{r, fig.width= 8, fig.height= 4}
read.csv("./Data/tables/hourly type duration.csv") %>% select(hour,type,d.med) %>%  accumulate_by(~ hour) %>%
  plot_ly(., x = ~ hour, y = ~ d.med, frame = ~ frame, colors= c("hotpink","black","steelblue"),
        color = ~ type, type ="scatter", mode = 'lines+markers',
        line = list(width=4,simplyfy = F), marker = list(size=10),
        text = ~paste("Hour: ",hour, '<br>Average duration:', round(d.med,2))) %>%
  layout(title = 'Hourly Median Trip Duration',
         yaxis = list(title = 'Duration (Min)', zeroline = FALSE),
         xaxis = list(title = 'Hour', zeroline = FALSE)) %>% 
  animation_opts(frame = 300, transition = 200, redraw = F) %>%
  animation_slider(hide = T) %>%
  animation_button(x = 1, xanchor = "right", y = 0, yanchor = "bottom")
```

```{r, results="hide", fig.width= 8, fig.height= 4}
read.csv("./Data/tables/wday type duration.csv") %>%
  select(-X) %>%
  mutate(wday = ordered(wday,levels = lvl)) %>%
  accumulate_by(~ wday) %>%
  arrange(wday) %>%
plot_ly(., x = ~ wday, y = ~ d.med,  colors= c("hotpink","black","steelblue"), color = ~ type,
        type ="scatter", mode = 'lines+markers',line = list(width=4,simplyfy = F), marker = list(size=10),
        text = ~paste("WeekdayHour: ",wday, '<br>Median duration:', round(d.med,2))) %>%
  layout(title = 'Weekday Median Trip Duration',
         yaxis = list(title = 'Duration (Min)',zeroline = FALSE),
         xaxis = list(title = 'Weekday', zeroline = FALSE))
```

```{r, fig.width= 8, fig.height= 4}
read.csv("./Data/tables/month type duration.csv") %>%
  select(-X) %>%
  mutate(month = match(month,month.abb)) %>%
  accumulate_by(~ month) %>%
  arrange(month) %>%
  plot_ly(., x = ~ month, y = ~ d.med, colors= c("hotpink","black","steelblue"),
          frame = ~ frame, color = ~ type, type ="scatter", mode = 'lines+markers',
          line = list(width=4,simplyfy = F), marker = list(size=10),
          text = ~paste("Month: ",month, '<br>Median duration:', round(d.med,2))) %>%
  layout(title = 'Monthly Median Trip Duration',
         yaxis = list(title = 'Duration (Min)',zeroline = FALSE),
         xaxis = list(title = 'Month', zeroline = FALSE))%>% 
  animation_opts(frame = 300, transition = 200, redraw = F) %>%
  animation_slider(hide = T) %>%
  animation_button(x = 1, xanchor = "right", y = 0, yanchor = "bottom")
```


We find:

* For typical day, Uber, Lyft and Via have simmilar trip duration in each hour.
* For weekly base, Lyft has a litter higher trip duration than others, especially on Monday (interesting!).
* For monthly base, Via's median duration is the highest because most trips are share riders, which takes longer time.
* Overall, Uber has lowest trip duration comparing other two!

### 5.3 Market Share

We also study the market shares on the both space and time line. We create an interactive [NYC FHV Marketshare map](https://zxf71699.carto.com/builder/62d8c815-2839-41fe-95e0-84ac6e4eccb6/embed) to indictate percentage of marketshare for Uber, Lyft and Via at different pick up zone. By simply clicking the map, you can see marketshare data in each zone. The legend lies in the right hand side, where you can also alter different views for each types of taxi by clicking three Teardrop-shaped buttons of applying auto style.

![NYC FHV Marketshare map](https://zxf71699.carto.com/builder/62d8c815-2839-41fe-95e0-84ac6e4eccb6/embed)](./Analysis/interactive market share.jpg)

```{r, fig.width= 8, fig.height= 4}
x = read.csv("./Data/tables/counts by h_wk_type.csv") %>%
  group_by(hour,type) %>%
  summarise(counts = sum(n))

y = read.csv("./Data/tables/counts by h_wk_type.csv") %>%
  group_by(hour) %>%
  summarise(total = sum(n))

inner_join(y, x, by = "hour") %>% 
  mutate(weight = round(100*counts/total,2)) %>% 
  select(type, weight, hour) %>%
  dcast(., hour ~ type, value.var = 'weight') %>%
  plot_ly(., x = ~ hour, y = ~ Uber, type = "scatter", mode = "lines+markers",
          groupnorm = 'percent', fill = 'tozeroy', fillcolor = "black",
          name = 'Uber', line = list(color='black'), marker = list(color = 'black'),
          text = ~ paste("Hour:", hour, "<br>Marketshare for FHV taxi:",Uber,"%")) %>%
  add_trace(y = ~ Lyft, name = 'Lyft', fillcolor = 'hotpink', 
            marker = list(color = 'hotpink'), line = list(color='hotpink'),
            text = ~ paste("Hour:",hour, "<br>Marketshare for FHV taxi:", Lyft,"%")) %>%
  add_trace(y = ~Via, name = 'Via', fillcolor = 'steelblue', marker = list(color = 'steelblue'),
            line = list(color='steelblue'),
            text = ~ paste("Hour:",hour, "<br>Marketshare for FHV taxi:",Via,"%"))%>%
  layout(title = 'Hourly marketshare for FHV types',hovermode = 'compare',
         yaxis = list(title = 'Marketshare', zeroline = FALSE, showgrid = F,ticksuffix = '%'),
         xaxis = list(title = 'Hour', zeroline = FALSE, showgrid = F)) 
```


We then research on hourly, weekly marketshare of Uber, Lyft and Via. We plot the following filled line plot and bar plot to observe whether there are some patterns or not.

```{r, results="hide", fig.width= 8, fig.height= 4}
x = read.csv("./Data/tables/counts by h_wk_type.csv") %>%
  mutate(wday = ordered(wday, levels = lvl[seq(7,1)])) %>%
  group_by(wday,type) %>%
  summarise(counts = sum(n))

y = read.csv("./Data/tables/counts by h_wk_type.csv") %>%
  mutate(wday = ordered(wday, levels = lvl[seq(7,1)])) %>%
  group_by(wday) %>%
  summarise(total = sum(n))

inner_join(y, x, by = "wday") %>% 
  mutate(weight = round(100*counts/total,2))%>% 
  select(type, weight, wday) %>%
  dcast(., wday ~ type, value.var = 'weight') %>%
  plot_ly(., x = ~ Lyft, y = ~ wday, type = 'bar', orientation = 'h',
          groupnorm = 'percent', fill = 'tozeroy', name = 'Lyft',
          line = list(color='hotpink'), marker = list(color = 'hotpink'),
          text = ~paste("Weekday:",wday, "<br>Marketshare for FHV taxi:", Lyft,"%")) %>%
  add_trace(x = ~Via, name = 'Via', marker = list(color = 'steelblue'),
            line = list(color='steelblue'),
            text = ~paste("Weekday:", wday, "<br>Marketshare for FHV taxi:",Via,"%")) %>%
  add_trace(x = ~ Uber, name = 'Uber', marker = list(color = 'black',opacity=0.7),
            line = list(color='black'),
            text = ~paste("Weekday:",wday, "<br>Marketshare for FHV taxi:",Uber,"%")) %>%
  layout(hovermode = 'compare',barmode = 'stack',title='Weekly marketshare for FHV types',
         yaxis = list(title = 'Marketshare', zeroline = FALSE),
         xaxis = list(title = 'Weekday', zeroline = FALSE, ticksuffix = '%'))
```

We find:

* Space Aspect
    + Service provided by Uber covers almost the whole area and it dominates the market.
    + Lyft makes up no more than 40% market among these four types in each pick-up zone. Service operates well
    mainly in midtown and downtown and some area of Brooklyn.
    + Via serve a smaller area in NYC and most zone only have no more than 10% Via trips. The interesting point
    is that Via makes up 100% marketshare in Newark Airport, but we think it is not realistic and  maybe data
    of Uber and Lyft did not cover Newark Airport.
    
* Time Aspect
    + Uber is dominant on the FHV market, reaching 75% in entire area.
    + Lyft is second dominant on the FHV market, and weekends have higher numbers of trips.
    + Via is a growing company and it takes a small proportion of market, but it focuses on the peaking hour
    and weekday. It make sense because Via offers packages at weekdays for workers and students.

### 5.4 Weather Effect

We have encouraged to supplement our analysis with combining the external NYC weather data to study how weather impacted on the trip duration. The particular interest here will be the rainny, snowny, sleeting(mixture of snow and rain) and sunny weather. We ploted box plot to observe the distribution of trip durations in these four weather conditions and we generated a bar plot for the number of trip requests for different weather respectively. Note that there are about 25k+ trips with durations larger than 60 miniutes which only made up 0.012% of the whole dataset, so we remove those records for better visualization purpose.

```{r, fig.width=8, fig.height=4}
df_rain = fread("./Data/tables/df_rain.csv") %>% as.tibble()
df_snow_rain = fread("./Data/tables/df_snow_rain.csv") %>% as.tibble()
df_sunny = fread("./Data/tables/df_sunny.csv") %>% as.tibble()
df_snow = fread("./Data/tables/df_snow.csv") %>% as.tibble()

plot_ly(type = 'box') %>%
  add_boxplot(x = df_rain$duration, name = "Rainy Days", fillcolor = 'rgba(254,231,37,0.4)',
              marker = list(color = 'rgba(219, 64, 82, 1.0)'),
              line = list(color = 'rgba(253,231,37,100)')) %>%
  add_boxplot(x = df_snow_rain$duration, name = "Snowy and Rainy Days",fillcolor = 'rgba(93,200,99,0.4)',
              marker = list(color = 'rgba(219, 64, 82, 1.0)'),
                            line = list(color = 'rgba(93,200,99,100)')) %>%
  add_boxplot(x = df_sunny$duration, name = "Sunny Days", fillcolor = 'rgba(33,144,140,0.4)',
              marker = list(color = 'rgba(219, 64, 82, 1.0)'),
              line = list(color = 'rgba(33,144,140,100)')) %>%
  add_boxplot(x = df_snow$duration, name = "Snowy Days", fillcolor = 'rgba(59,82,39,0.4)',
              marker = list(color = 'rgba(219, 64, 82, 1.0)'),
              line = list(color = 'rgba(59,82,39,100)')) %>%
  layout(title = "Weather Effects on Trip Duration", hovermode = 'compare',
          yaxis = list(title = '', zeroline =T, showgrid = T),
          xaxis = list(title = 'Duration (Min)', zeroline = T, showgrid = T))
```


```{r, fig.width=8, fig.height=4, results="hide"}
read.csv("./Data/tables/weather counts.csv") %>%
plot_ly(type = 'bar') %>%
  add_bars(x = ~ 82545120, y= "Rainy Days",name = "Rainy Days", fillcolor = 'rgba(254,231,37,0.4)',
           marker = list(color = 'rgba(254,231,37,0.4)'),
           line = list(color = 'rgba(253,231,37,100)'),
           text = ~paste("weather:","Rainy Days","<br>Trip counts:",82545120)) %>%
  add_bars(x = ~5111354,   y= "sleeting Days",
           name = "Snowy and Rainy Days", fillcolor ='rgba(93,200,99,0.4)',
           marker = list(color = 'rgba(93,200,99,0.4)'),
           line = list(color = 'rgba(93,200,99,100)'),
           text = ~ paste("weather:","Snowy and Rainy Days","<br>Trip counts:",5111354))%>%
  add_bars(x = ~ 111272091, y = "Sunny Days", name = "Sunny Days", fillcolor = 'rgba(33,144,140,0.4)',
           marker = list(color = 'rgba(33,144,140,0.4)'),
           line = list(color = 'rgba(33,144,140,100)'), 
           text = ~paste("weather:","Sunny Days","<br>Trip counts:",111272091)) %>%
  add_bars(x = ~437323, y= "Snowy Days",name = "Snowy Days", fillcolor = 'rgba(59,82,39,0.4)',
              marker = list(color = 'rgba(59,82,39,0.4)'),
              line = list(color = 'rgba(59,82,39,100)'),
           text = ~paste("weather:","Snowy Days","<br>Trip counts:",437323)) %>%
  layout(title = "Weather Effect on Trip Counts",
          yaxis = list(TITLE="Weather", zeroline = FALSE, showgrid = T),
          xaxis = list(title = 'Trip Counts', zeroline = F, showgrid = T))
```

We find:

* For sunny days, there are the largest amount of trip requests. It tells most people prefer to hang out.
* Rain causes the larger amount order requests and longer trip duration 
* For snowy days, there are a few outliers, so it might tells more likely occurs extremely cases in the bad weather.
* It is more likely that snow would lead to shorter trips, so it could simply mean passengers were more likely to travel shorter distances, or stay at home.

## VI. Conclusion

We conclude:

* FHV data has about 90k missing value. Since we have very large dataset, removing missing value will be better idea.
* The trip exists a lot of outliers (duration <= 2 mins and >= 4 hours), so we need to investigate on the specific direction and time consumption to identify the possiblity.
* The duration is heavy skew, so we require **log** transformation to normal distribution for future modeling.
* In general, trip durations fluctuate all day and long trips happen at rush hour which makes sense. Interesting point is that longer trips happen in Thursday, it may be worth further investigation though. We also found trips with longer duration occurs in May and Oct when a larger number of vistors come to the city.
* Overall, Via ususally have longer duration because they offer a large number of shared ridd and Uber seems has lowest trip durations. But in weekly base, Lyft generally takes more time for trips except weekend.
* It is obvious that Uber still dominate the FHV market. Via offer services in limitted areas compared to others. But it is interesting that Lyft shares less market during rush hour and weekdays. We guess that lots of Lyft drivers may be part-time and they may be out of service during weekdays or rush hour.
* Although distribution of trip durations is quite similar for these four weathers. The interesting point is that median of trip durations in sunny days are slightly larger than others.

Future Thoughts:

* We can expend our data time frame such that collect and combine the latest three years data to study the pattern.
* It will be a good idea to estimate the distance betweeen each location block, so we can analyze the medican speed, which might be more intuition.
* The yellow and green cabs also have a big proportion of market share, and directly collected by goverment, so the data is more accurate and reflect to reality.
* Another concern is that rainy days are much less than sunny days, so we should normalize the trips by weather days, which might be more make sense.
* I found the paper said: the minimum and maximum temperatures show a strong correlation with each other because it also reflects to the the quality of weather and human behavior. We should include the temeratures to visualize the impact on trip duration.